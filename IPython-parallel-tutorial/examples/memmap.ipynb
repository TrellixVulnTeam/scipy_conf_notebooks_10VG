{
 "metadata": {
  "name": "",
  "signature": "sha256:688993a555a5450c12af8b8843dad50f2b78cac0f389adedc2f133aa556908cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "More efficient broadcast of arrays with memmap"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data movement is where IPython's na\u00efve model suffers the most.\n",
      "But knowing about your cluster lets you make smarter decisions about data movement than a simple `rc[:].push`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import socket\n",
      "import os, sys, re\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from IPython import parallel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = parallel.Client(profile='dirac')\n",
      "eall = rc[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine_hosts = eall.apply_async(socket.gethostname).get_dict()\n",
      "engine_hosts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "host_engines = {}\n",
      "\n",
      "for eid, host in engine_hosts.items():\n",
      "    if host not in host_engines:\n",
      "        host_engines[host] = []\n",
      "    host_engines[host].append(eid)\n",
      "\n",
      "host_engines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sz = 256\n",
      "data = np.random.random((sz,sz))\n",
      "data = data.dot(data.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time _ = rc[:].apply_sync(lambda : None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar = rc[:].push({'data': data}, block=False)\n",
      "ar.wait_interactive()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def array_to_file(A):\n",
      "    \"\"\"write an array to a temporary file, return its filename\"\"\"\n",
      "    import tempfile\n",
      "    with tempfile.NamedTemporaryFile(suffix='.np', delete=False) as tf:\n",
      "        np.save(tf, data)\n",
      "        data_path = tf.name\n",
      "    return data_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@parallel.interactive\n",
      "def load_memmap(name, path, mode='r+'):\n",
      "    \"\"\"load a file on disk into the interactive namespace as a memmapped array\"\"\"\n",
      "    globals()[name] = np.memmap(path, mode=mode)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bcast_memmap(data, name, client, host_engines):\n",
      "    \"\"\"broadcast a numpy array efficiently\n",
      "    \n",
      "    - sends data to each remote host only once\n",
      "    - loads with memmap everywhere\n",
      "    \"\"\"\n",
      "\n",
      "    # actually push the data, just once to each machine\n",
      "\n",
      "    local_filename = None\n",
      "    filenames_ars = {}\n",
      "    for host, engines in host_engines.items():\n",
      "        h0 = engines[0]\n",
      "        if host == socket.gethostname():\n",
      "            # Don't push at all to local engines\n",
      "            local_filename = array_to_file(data)\n",
      "        else:\n",
      "            filenames_ars[host] = rc[h0].apply_async(array_to_file, data)\n",
      "\n",
      "    # load the data on all engines into a memmapped array\n",
      "    msg_ids = []\n",
      "    for host, engines in host_engines.items():\n",
      "        if host == socket.gethostname():\n",
      "            filename = local_filename\n",
      "        else:\n",
      "            filename = filenames_ars[host].get()\n",
      "        ar = rc[engines].apply_async(load_memmap, name, filename)\n",
      "        msg_ids.extend(ar.msg_ids)\n",
      "    \n",
      "    return parallel.AsyncResult(client, msg_ids=msg_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "ar = bcast_memmap(data, 'data', rc, host_engines)\n",
      "ar.wait_interactive()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px np.linalg.norm(data, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also do the same thing [with MPI](MPI Broadcast.ipynb)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}